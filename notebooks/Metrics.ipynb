{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf14ef00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T06:55:03.364210Z",
     "start_time": "2022-06-02T06:55:03.358252Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import gensim\n",
    "import requests\n",
    "import html2text\n",
    "import wikipedia\n",
    "import smart_open\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    VisionEncoderDecoderModel,\n",
    "    ViTFeatureExtractor,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    pipeline,\n",
    ")\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_path = \"../../data\"\n",
    "\n",
    "test_data_dir = os.path.join(gensim.__path__[0], 'test', 'test_data')\n",
    "lee_train_file = os.path.join(test_data_dir, 'lee_background.cor')\n",
    "lee_test_file = os.path.join(test_data_dir, 'lee.cor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5092f8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T06:36:20.784116Z",
     "start_time": "2022-06-02T06:36:20.620413Z"
    }
   },
   "outputs": [],
   "source": [
    "root_path = os.path.join(data_path, \"okvqa\")\n",
    "\n",
    "test_questions_path = os.path.join(root_path, \"OpenEnded_mscoco_val2014_questions.json\")\n",
    "test_annotations_path = os.path.join(root_path, \"mscoco_val2014_annotations.json\")\n",
    "test_image_path = os.path.join(root_path, \"val2014\")\n",
    "test_image_name_prefix = \"COCO_val2014_000000\"\n",
    "\n",
    "with open(test_questions_path, \"r\") as f:\n",
    "    test_questions_df = pd.DataFrame(json.load(f)[\"questions\"])\n",
    "    \n",
    "with open(test_annotations_path, \"r\") as f:\n",
    "    test_annotations_df = pd.DataFrame(json.load(f)[\"annotations\"])\n",
    "    \n",
    "test_df = test_questions_df.merge(test_annotations_df)\n",
    "test_df[\"image_path\"] = test_df[\"image_id\"].map(lambda image_id: os.path.join(test_image_path, f\"{test_image_name_prefix}{image_id:06d}.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b4d8782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T06:36:45.425574Z",
     "start_time": "2022-06-02T06:36:20.786202Z"
    }
   },
   "outputs": [],
   "source": [
    "qa_model = AutoModelForQuestionAnswering.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "qa_tokenizer = AutoTokenizer.from_pretrained(\"deepset/roberta-base-squad2\")\n",
    "\n",
    "ic_model = VisionEncoderDecoderModel.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "ic_feature_extractor = ViTFeatureExtractor.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "ic_tokenizer = AutoTokenizer.from_pretrained(\"nlpconnect/vit-gpt2-image-captioning\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "qa_model = qa_model.to(device)\n",
    "ic_model = ic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63b99ef8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:37:42.729465Z",
     "start_time": "2022-06-02T07:37:42.710223Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    i_image = Image.open(image_path)\n",
    "    if i_image.mode != \"RGB\":\n",
    "        i_image = i_image.convert(mode=\"RGB\")\n",
    "\n",
    "    return i_image\n",
    "\n",
    "def get_wikipedia_page(string):\n",
    "    try:\n",
    "        p = wikipedia.summary(string, auto_suggest=False)\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        s = e.options[0]\n",
    "        p = wikipedia.summary(s, auto_suggest=False)\n",
    "\n",
    "    return p\n",
    "\n",
    "def get_context(caption, use_wikipedia=True):\n",
    "    if use_wikipedia:\n",
    "        words = word_tokenize(caption)\n",
    "        tags = pos_tag(words)\n",
    "\n",
    "        tags = [w for (w, t) in tags if t[0] == \"N\"]\n",
    "\n",
    "        options = list(set([o for tag in tags for o in wikipedia.search(tag, results=1)]))\n",
    "        pages = [caption] + [get_wikipedia_page(option) for option in options]\n",
    "        \n",
    "        return \"\\n\".join(pages)\n",
    "    \n",
    "    return caption\n",
    "\n",
    "def get_caption(\n",
    "    ic_model,\n",
    "    ic_feature_extractor,\n",
    "    ic_tokenizer,\n",
    "    image,\n",
    "    max_length=16,\n",
    "    num_beams=4,\n",
    "):\n",
    "    pixel_values = ic_feature_extractor(\n",
    "        images=[image], return_tensors=\"pt\"\n",
    "    ).pixel_values\n",
    "    pixel_values = pixel_values.to(ic_model.device)\n",
    "\n",
    "    output_ids = ic_model.generate(\n",
    "        pixel_values, max_length=max_length, num_beams=num_beams\n",
    "    )\n",
    "\n",
    "    preds = ic_tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    return preds[0]\n",
    "\n",
    "def get_answer(qa_model, qa_tokenizer, question, context):\n",
    "    qa_pipeline = pipeline(\"question-answering\", model=qa_model, tokenizer=qa_tokenizer)\n",
    "    result = qa_pipeline(question, context)\n",
    "\n",
    "    return result\n",
    "\n",
    "def run(\n",
    "    ic_feature_extractor,\n",
    "    ic_model,\n",
    "    ic_tokenizer,\n",
    "    qa_model,\n",
    "    qa_tokenizer,\n",
    "    image,\n",
    "    question,\n",
    "    max_length=16,\n",
    "    num_beams=4,\n",
    "    use_wikipedia=True\n",
    "):\n",
    "    caption = get_caption(\n",
    "        ic_model,\n",
    "        ic_feature_extractor,\n",
    "        ic_tokenizer,\n",
    "        image,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams,\n",
    "    )\n",
    "    context = get_context(caption, use_wikipedia=use_wikipedia)\n",
    "    answer = get_answer(qa_model, qa_tokenizer, question, context)\n",
    "\n",
    "    return caption, answer, context\n",
    "\n",
    "def mk_predictions(index, use_wikipedia=True):\n",
    "    question, image_path, answers = test_df[[\"question\", \"image_path\", \"answers\"]].iloc[index]\n",
    "    image = read_image(image_path)\n",
    "    caption, answer, context = run(ic_feature_extractor, ic_model, ic_tokenizer, qa_model, \n",
    "                                   qa_tokenizer, image, question, use_wikipedia=use_wikipedia)\n",
    "    \n",
    "    return answer, answers\n",
    "\n",
    "def get_similarity(doc2vec, pair):\n",
    "    answer, answers = pair\n",
    "    \n",
    "    result = 0\n",
    "    for ans in list(set([a['answer'] for a in answers])):\n",
    "        r = doc2vec.similarity_unseen_docs(word_tokenize(answer[\"answer\"]), word_tokenize(ans))\n",
    "        if r > result:\n",
    "            result = r\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compute_score(doc2vec, predictions, threshold=0.5):\n",
    "    total = len(predictions)\n",
    "    count = 0\n",
    "    \n",
    "    for pair in predictions:\n",
    "        if get_similarity(doc2vec, pair) >= threshold:\n",
    "            count += 1\n",
    "            \n",
    "    return count / total\n",
    "\n",
    "def compute_compare_score(doc2vec, predictions1, predictions2):\n",
    "    total = len(predictions)\n",
    "    count = 0\n",
    "    \n",
    "    for (answer1, answers), (answer2, answers) in zip(predictions1, predictions2):\n",
    "        result1 = get_similarity(doc2vec, (answer1, answers))\n",
    "        result2 = get_similarity(doc2vec, (answer2, answers))\n",
    "        \n",
    "        if result1 >= result2:\n",
    "            count += 1\n",
    "            \n",
    "    return count / total\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "    with smart_open.open(fname, encoding=\"iso-8859-1\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e91b06d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T06:36:47.263114Z",
     "start_time": "2022-06-02T06:36:45.463787Z"
    }
   },
   "outputs": [],
   "source": [
    "train_corpus = list(read_corpus(lee_train_file)) + list(read_corpus(lee_test_file))\n",
    "\n",
    "doc2vec = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
    "doc2vec.build_vocab(train_corpus)\n",
    "doc2vec.train(train_corpus, total_examples=doc2vec.corpus_count, epochs=doc2vec.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49f95c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:23:01.089421Z",
     "start_time": "2022-06-02T07:13:57.051002Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [09:04<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    predictions.append(mk_predictions(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60b63a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:23:01.765475Z",
     "start_time": "2022-06-02T07:23:01.091024Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(doc2vec, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b823fba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:23:02.417916Z",
     "start_time": "2022-06-02T07:23:01.767033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(doc2vec, predictions, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc21b96a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:28:01.419438Z",
     "start_time": "2022-06-02T07:23:02.420045Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [04:58<00:00,  2.99s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions_2 = []\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    predictions_2.append(mk_predictions(i, use_wikipedia=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22d40d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:28:02.137041Z",
     "start_time": "2022-06-02T07:28:01.421386Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(doc2vec, predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41819849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:28:02.773071Z",
     "start_time": "2022-06-02T07:28:02.138334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(doc2vec, predictions_2, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7831a633",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T07:37:48.509104Z",
     "start_time": "2022-06-02T07:37:47.366849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_compare_score(doc2vec, predictions, predictions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3b7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
